{
  "student_name": "None None",
  "org_defined_id": "037604525",
  "username": "gupt1107",
  "video_url": "",
  "transcript": "Hi, my name is Abha Gupta and for my management 310 mini project 3, this is my AI finance tool built using Google AI studio and the Gemini API. It's designed for beginners who want a long-term conservative investment guidance explained in simple language. Now, the financial decision I wanted to support is what investment approach makes sense for someone's situation? Not just the math, but why behind it. People often struggle with understanding risk, time horizons, and trade-offs. So, my tool focuses on contextual explanations, not calculations. AI helps by letting users speak naturally. Like, for example, this prompt that's put in on the left side into Gemini, saying something like, \"I make $20,000. I have $3,000 saved, and I want to buy a house.\" Gemini interprets their goals, age, risk comfort, and a timeline and converts that into plain English recommendations, strategic reasoning, and jargon-free explanations. This is exactly what I implemented in the version one of my financial tool. It was a very simple integration. I connected the Gemini model, sent the user's input as a prompt, and the AI just returned an answer. It could explain decisions and give advice advice, but it lacked structure, trust features, and guard rails. So, I took some of these um issues or places that we could build upon and I made it better in version two. In version two, I focused on making the tool trustworthy, structured, and more aligned with real financial advising workflows. Instead of just producing generic text responses, I implemented three major upgrades. One, structured reasoning output. instead of a free form answer that was put in um version one where this AI bot over here on this left side would kind of just give a general advice. Um I had version two implement an output a well organized four-part structure using markdown headings. So one summary of the user situation. This ensures the tool restates the user's age, savings, um, time horizon, and goals so the user can confirm the AI understood the context correctly. A scenario comparison table. I added um, if you can look over here, here's a summary. Again, as well, I added a markdown table with three scenarios: conservative, balanced, aggressive, each with stock, bonds, and cash percentages, risk level score, key pros and cons. This is a this creates a visually clear side-by-side comparison that is easy for beginners to understand. It also counts as structured output with validation, which is part of the assignment's advanced capabilities requirement. Three, a recommended scenario and rationale. The model must tie its recommendation back to the user's specific profile, income level, savings rate, time horizon, and risk comfort, making the advice highly contextual. Four, a sanity check and limitation section. This explicitly reviews whether the user's goals and risk preferences match their timeline and flags anything unrealistic. For example, trying to buy a house in three years with only $1,000 saved. This satisfies the trust and safety component of loop 2. Two built-in guard rails to prevent harmful advice. I added a strong anti-risk rules inside the system instructions. The model cannot recommend leverage, options trading, day trading, or crypto speculation. If a user asks for unrealistic returns like, \"How do I turn $1,000 into $100,000 fast?\" The model is is required to politely refuse and explain why that is dangerous. It must always include a standardized clear disclaimer at the end. As you can see here, these guard rails directly address the requirement for sanity checks, misuse protection, safety and accuracy, and ethical considerations. Three, improved prompt engineering for liability. Finally, I refined the prompt to make the model more deterministic and consistent. Without structure, Gemini might hallucinate or give overly general answers. But with version two instructions, the answer is predictable every time. It always uses the same four sections. It always gives three scenarios. It always gives a recommendation. It always runs a sanity check. And it always concludes with a disclaimer. This ensures um that it goes beyond a single prompt and shows iterative improvement towards a safer, more useful AI tool.\nTo verify the tool, I tested multiple real scenarios, low income, short-term horizon, different risk tolerances, and checked whether Gemini Hallucinated or gave irresponsible advice. The guardrails worked. It refused high-risisk requests and always defaulted to safe educational explanations. The one that I've listed just over here is a very basic um pretty average explanation just to show some of the answers. If I had more time, I'd expand the tool with an external API data like market rate, market rates or inflation trends, a profile memory system so the user can refine their plan over multiple messages or optional charts or JSON outputs for visualizations. Working with AI changed this experience completely. Instead of forcing users through rigid forms, they can talk naturally and still receive structured personal guidance. The hardest part of this, I would say, was the prompt engineering section, especially making the AI consistent, conservative, and not speculate. I had to explicitly design guard rails to prevent risky suggestions. Now, um, for ethics, I made sure to have clear disclaimers, reinforce that this is completely educational and not financial advice that you should be taking seriously or completely only trust, and also included sanity checks to avoid misleading users. The real question is, would I trust this with my money? I would say not entirely. It's not a final decision maker, but I would use it to understand options, compare scenarios, and prepare questions for a real financial adviser. And that's my AI finance tool, a financial guide for beginners. It's a structured, mostly trustworthy assistant for beginners looking for some long-term investment guidance. Thank you."
}