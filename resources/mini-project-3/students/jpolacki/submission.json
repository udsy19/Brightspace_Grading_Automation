{
  "student_name": "None None",
  "org_defined_id": "035981714",
  "username": "jpolacki",
  "video_url": "",
  "transcript": "Hi, my name is Jacob Polackin. I'm a junior here at Purdue, and today I'm going to be talking about what I made for Mini-Project 3. This is the Financial Reality Checker. I noticed a problem: college students often set financial goals, like \"I want to buy a car\" or \"save for a trip,\" without understanding the math or the market conditions required to get there. I didn't just want a calculator; I wanted a tool that thinks. My tool acts as a rational second brain. It pulls live market data, analyzes feasibility, and acts as a compliance officer to prevent dangerous financial decisions. So, moving into the \"how,\" this is my V1, the first model I made to address this. As you can see, there's a simple form. When I click \"Execute Workflow,\" a form pops up requesting monthly income, monthly expenses, the item they want to buy, and the price of that item. Looking at the workflow configuration, we have the form trigger, the AI node, and the output parser. Let's do a basic example for a college student. We'll say monthly income is $150, monthly expenses are $50, and they are trying to buy a nice dinner for $80. We submit the form, and the workflow runs through the nodes. The financial advisor AI uses the Gemini chat model with my API key. The results populate here, going into detail and noting that the $80 dinner represents 53% of monthly income and 80% of disposable income. It calculates that 0.8 months of disposable income would be required. It even provides a savings model and financial feasibility criteria, classifying this purchase as \"moderate,\" which is really detailed and nice. That was V1. Moving on to the more advanced version, here is the Finance Tool V2. This one is much more in-depth. It starts with the Financial Goal Form where the user states their goal. The HTTP Request node is the first advanced capability, connecting to the Frankfurter API for live currency exchange rates. This ensures advice is based on current economic context, not just static training data. The Basic LLM Chain acts as the senior advisor, running Google Gemini Flash. I used prompt engineering to give it specific instructions: if a user is vague about their timeline, the AI must generate three distinct scenarios—aggressive, moderate, and relaxed—rather than just giving up. The compliance node acts as a safety mechanism; if the AI detects an illegal or financially irresponsible request, it cuts the workflow immediately. Finally, JavaScript nodes parse the raw JSON into a readable dashboard. Let's execute an example. We'll set a savings goal for a spring break trip to Europe with a target amount of $5,000. Since spring break is close, we'll say the timeframe is four months. Income is $500, expenses are $50. Let's analyze this goal. The output shows the feasibility is \"Refused.\" The monthly savings needed is $1,250, but the risk warning notes that current available savings of $450 is substantially less than the required amount. It also notes that the Euro is stronger than the Dollar, making travel expenses more costly. It advises drastically increasing income, extending the timeframe, or reducing the budget. Now, let's test the timeline flexibility. We'll use the same goal—$5,000 trip to Europe, $500 income, $50 expenses—but we will leave the timeframe blank to see how it handles aggressive and moderate strategies. In this scenario, feasibility is high. It outlines an aggressive strategy of $416 a month for 12 months, a moderate strategy of $277 a month for 18 months, and a relaxed strategy of roughly $208 a month for 24 months. It warns that the Euro is strong and that the main risk is not consistently saving the available $450. The advice suggests a \"pay yourself first\" strategy, setting up automatic transfers to a separate savings account to reduce temptation. This is definitely a more evolved version of my model showing risk warnings and different strategies. As we near the end, I want to share my reflection. First, how does AI change the user experience? Traditionally, financial tools are static: fixed input, fixed output. AI shifts this from a transaction to a conversation. My tool acts as a senior analyst handling ambiguity. If I don't know when I want to travel, it doesn't break; it proactively suggests three scenarios, turning a rigid data entry process into a dynamic advisory experience. Regarding prompt engineering, the hardest part was enforcing structure over personality. LLMs naturally want to chat in paragraphs, but for this tool, I needed precise, machine-readable data. Regarding ethical considerations, the biggest challenge was the fiduciary gap—the risk that a user might mistake this AI for a certified financial planner. To mitigate this, I built the compliance guardrail to block illegal requests and included mandatory risk warnings to force the AI to point out downsides like inflation or currency fluctuations. Finally, would I trust it with real money? I would trust it as a second opinion, but not the final decision. I trust the math logic and the live market data, but I wouldn't trust AI with complex execution as it can hallucinate. I would use this for a rough draft but verify specific numbers with a bank before moving real capital. Thank you so much for listening."
}