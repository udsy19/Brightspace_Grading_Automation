{
  "student_name": "Abbey Carroll",
  "org_defined_id": "035875419",
  "username": "carro146",
  "email": "",
  "transcript": "Hello. So, in today's video, I am going to be walking through a complete riskmanagement overhaul using the driver framework. So, I'm acting as the risk manager for a hedge fund that recently experienced an unexpected 8% 1-day loss, something our older system failed to detect to detect. My goal is to rebuild the firm's risk monitoring system using value at risk, expected shortfall, and stress testing, and to walk through the code cell by cell while explaining how each part contributes to a more resilient risk process. So for section zero, setup um discover loading libraries and initial setup. So first I start by importing all of the libraries needed for the analysis. So the nump py pandas map plot lib sepy and y finance. I also set formatting preferences to keep output clean and reproducible. This cell doesn't produce much visual output. That's normal but it sets up everything the rest of the notebook relies on. So then for section one data download that is for our discover pulling market data. So in the discover phase, I gather the data that will feed into the risk framework. I download daily prices for five large US equities. Apple, Microsoft, Amazon, Google, and JP Morgan. This set gives the portfolio a realistic tilt towards large cap tech with a financial stabilizer. The output shows that I downloaded about 3,991 rows of clean price data. The tail of the data set displays the most recent trading dates and price levels. So then for our section two returns and stats, this is for our represent phase transforming prices into returns. So next I compute daily log returns which are preferred format for risk modeling because they're mathematically convenient and behave well in volatility modeling. The tail of the return data set confirms the transformation worked correctly. Then I annualize mean returns, volatility, and the full correlation matrix. So the annualized returns range from roughly 15 to 24%. While volatilities sit between 25 to 33%. The correlation matrix shows all assets are positively correlated. This will matter later when we think about diversification and VR. So then for our section three that is our portfolio construction and this is also for a represent phase. So defining weights in portfolio design or returns. So now I define the actual portfolio. I'll be analyzing 25% AAPL, 25% Microsoft, 20% Amazon, 15% Google, and 15% JP Morgan. So this gives the portfolio a heavy but realistic tech tilt. The portfolio daily return summary shows mean daily return is around um 0.8%, daily volatility is around 1.39%. And the worst historical day is about 12.82%. That worst day will resurface when we examine stress testing. So next for section four portfolio value plot. So this is also for the represent stage which is visualizing portfolio behavior. So I simulate 10 million investment starting in 2010. The plot shows long run growth into the tens of millions, but with significant down draw or draw downs during the 2018 volatility spike, the COVID crash and the periodic tech sell-offs. This makes clear that even high-erforming portfolios need strong risk controls. So next for section five, that is our historical VAR. So that is for our implement now empirical value at risk. So historical V directly uses the empirical return distribution. So for this $10 million portfolio, it's 95% V, which is around $224,000, and then the 99% V, which is around $390,000. So this means that historically the portfolio did not lose more than those amounts on 95% or 99% of trading days. So next for section six that is our parametric VAR. So this is for our implement as well normal distribution V. So now I calculate the variance co-variance V which assumes normality using the mean return and standard deviation means 95% parametric V is around $221,000 and 99% parametric V is around $316,000. So these are lower than the historical values especially at the 99%'s confidence level which hints at underestimation of tail losses by the normal model. Next for section seven, this is our CV which is also in the implement expected shortfall. So expected shortfall measures the average loss when we are already in the worst of days. So 95% of CV is around 323 is 323,000 and then our 99% CV is around $517,000. So these values are much larger than the corresponding V numbers highlighting deeper tail risk. So next for section 8 is the distribution plot. And this is for validate. So visual inspection of tail behavior. So I plot the return histogram and overlay the 95% and the 99% V cut offs. You can visually see the left tail is heavier than a normal distribution explaining why historical and CV values exceed normalbased V especially at high confidence levels. So next for section N that is our historical stress tests and this is also for validate stress testing against real events. So in this section I identified the worst 10 daily losses. So the worst day is March 16th 2020 and it was -12.82%. Most of the list comes from the COVID crash and a few additional severe draw downs appear in 2011 and 2022. So then I look at the major crisis windows. The GFC window shows no data due to my data set starting in 2010 and the COVID crash window shows a negative 11.63% cumulative loss with the worst day again at -12.82%. These results confirm that CO is the dominant stress event for this portfolio. So next is section 10 customer scenario tests or custom scenario tests. This is also for validate hypothetical shocks. So I then run these three hypothetical shock scenarios. So number one is 5% marketwide selloff. So this in turn cause the portfolio loses $500,000. Number two, tech crash. So, negative 10% tech, negative3% JPM. So, the portfolio loses $895,000. And then number three, financial crisis style shock. Portfolio loses $375,000. These scenarios highlight the portfolio sensitivity to tech and complement the crisisbased stress tests. So then for section 11 interpretation and recommendations. So this is for our interpret what all the metrics tell. So if we go down to the results from all VR, CVR and stress test results, parametric V systematically underestimates risk. CVR reveals deeper tail losses. Real world maximum loss of -12.82% 82% is far worse than any V estimate and co created a draw down consistent with the worst tail events. This leads into actionable recommendations. So setting daily V limits tied to AUM use stop loss or degrossing rules add concentration limits on tech and combine V plus ES plus stress test plus liquidity metrics. So no single metric is sufficient alone. And then for section 12, our final section, limitations of V. So this is for our reflect why V must be part of a bigger F or a bigger system. So finally I explained the limitations of V. Um number one, model assumptions rarely match reality. Number two, V ignores what happens beyond the cutoff. Number three, V shrinks in calm markets and spikes in volatile ones. Number four, V ignores liquidity. And number five, VR struggle or V struggles with nonlinear portfolios. This is why modern risk management uses multiple metrics and not V in isolation. The purpose of this overhaul was to build a system that one identifies vulnerabilities, two quantifies extreme but plausible losses, three establishes risk limits and governance, and four prevents future unexpected drawdowns like the 8% loss that triggered this analysis. And this completes the full driver cycle for implementing V and stress testing. Thank you.",
  "video_url": "https://youtu.be/1NzUVQpCzCQ"
}