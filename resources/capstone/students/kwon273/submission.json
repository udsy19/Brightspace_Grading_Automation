{
  "student_name": "Anthony Kwon",
  "org_defined_id": "036288518",
  "username": "kwon273",
  "video_url": "https://youtu.be/n1xLKrmAsmo",
  "transcript": "I built an AI-powered financial explanation tool designed for non-finance stakeholders.\nThe problem I wanted to solve is that financial results are often communicated using jargon and metrics that make sense to analysts, but not to managers, founders, or operators who still need to make decisions based on those numbers. Even when revenue and costs are clear, the \"why\" behind the changes is usually missing.\n\nThis tool takes basic financial inputs such as revenue and cost changes across two periods and turns them into a plain-English explanation using a large language model. The goal is not to calculate numbers, but to interpret them in a way that is immediately understandable.\n\nHere's how it works.\nA webhook receives structured financial data, including the company name, two comparison periods, revenue and cost figures, and optional business context. That data is then sent to Google's Gemini language model through an API call. The model is prompted to explain what changed, why it changed, and why it matters, specifically for a non-finance audience. The generated explanation is then returned instantly as the response.\n\nI built this using Make.com with three components: a webhook to receive inputs, an HTTP module that calls the Gemini API, and a webhook response that returns the AI-generated explanation. The entire system is interactive and works in real time.\n\nFor example, in this test case, revenue increased while costs rose even faster due to hiring more staff. Instead of just showing margin compression numerically, the AI explains that growth required upfront investment in people, which may pressure short-term profitability but could support future scaling. This kind of explanation helps decision-makers quickly understand trade-offs without needing a finance background.\n\nWhat I learned from building this is that the hardest part wasn't the financial logic, but getting the AI integration to work reliably. Understanding API versions, model compatibility, request structure, and error handling was critical. Once the system worked end to end, the value became very clear.\n\nThis tool could scale by adding features like variance thresholds, trend detection, or automatic slide-ready summaries for board decks. But even in its current form, it solves a real communication problem and is something I would actually use beyond this class.\nThe key takeaway from this project is that AI becomes most powerful when it's embedded into a workflow that people already need, rather than used for analysis alone. I didn't just analyze financial data â€” I built a system that explains it."
}