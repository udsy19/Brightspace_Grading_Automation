{
  "student_name": "Yanxi Liu",
  "org_defined_id": "038231480",
  "username": "liu4186",
  "video_url": "https://youtu.be/GaHbrSe4iiM",
  "transcript": "Hi, I'm Yanxi. This is my Capstone Project: Fed-Speak to Trading Signals Tool.\nI also followed the DRIVER framework.Begin with the define & discover. The purpose of this project is to address a persistent challenge in financial markets: Federal Reserve communications are intentionally complex, cautious, and often ambiguous, making them difficult for non-experts and even junior market participants to interpret. While professional traders may understand the nuances of \"Fed-speak,\" many students, retail investors, and early-career analysts struggle to translate official language into actionable market expectations.\nThe goal of this tool is to bridge that gap by transforming official Federal Reserve documents—such as FOMC statements, meeting minutes, press conference transcripts, and speeches—into clear, plain-English trading signals. Rather than predicting markets, the tool focuses on interpretation, helping users understand what the Fed's language implies for interest rates, the U.S. dollar, equities, credit conditions, and safe-haven assets.During the discovery phase, I examined how market participants react to different types of Fed communication. I observed that short documents like FOMC statements tend to move markets immediately, while longer texts such as minutes or speeches often influence expectations more gradually. I also identified repeated linguistic patterns—phrases like \"higher for longer,\" \"data-dependent,\" or \"balanced risks\"—that consistently signal shifts in policy tone. These observations shaped the tool's emphasis on language decoding rather than numerical forecasting.\nThe represent stage is to explain the problem clearly, I structured the tool around a simple input-output logic. The input consists of official Fed content provided by the user, either as pasted text, a document, or a link to an official Federal Reserve webpage. The output is a structured interpretation that translates the policy language into directional market signals.\nInternally, the model organizes information into several analytical layers: identifying the document type and context, extracting key policy themes, interpreting tone and changes in language, and mapping those interpretations to asset-class implications. This representation allows the tool to maintain consistency across different Fed documents while still adapting to their unique formats.\nThe output format is intentionally standardized, with sections for policy tone scoring, key phrase interpretation, trading signals, scenario analysis, and risk considerations. This design ensures that users can quickly scan the results while also understanding the reasoning behind each signal.At the implementation stage, the tool is implemented in Google AI Studio as a single-step workflow: the user pastes Fed text into the input box (or attaches a file) and clicks \"Generate Signals.\" In the example shown, the pasted text is a Fed speech excerpt about AI and macro/financial stability, including language such as \"too soon to tell\" and a warning that AI market sentiment and leverage could shift. Because the user did not provide a date or link, the tool explicitly labels the metadata as \"Date: Unknown\" and \"Source: Text,\" which keeps the output honest about what it can and cannot infer.\nAfter intake, the tool auto-classifies the content as a Speech and produces a short Document Snapshot stating that the speaker discusses AI's potential impact on the dual mandate (employment and price stability) and financial stability, with a comparison to the dot-com era. This matters for implementation because speeches often contain theme-setting and risk framing rather than direct near-term rate guidance, so the tool treats the signal strength as lower unless explicit policy language is present.Next, the tool generates a Policy Tone Scorecard (0–10). In this example, most categories remain moderate/neutral (hawkishness, inflation, labor), while financial stability scores visibly higher. That result is driven by the speech's emphasis on risk appetite, leverage, and the possibility of an \"unwinding\" in AI-related sentiment, which the tool treats as a financial-conditions risk channel rather than a rates signal.\nThe output then converts this into a Plain-Language Takeaway: AI could influence productivity, growth, and inflation, but the Fed does not commit to immediate policy implications and stresses uncertainty; meanwhile, financial stability is described as sound overall, but with rising concern among market contacts about AI-driven exuberance. This takeaway is intentionally written as a readable translation of the speech's main message, not a forecast.In the Trading Signals panel, the tool maps the speech into asset views and correctly stays Neutral across 2Y yields, 10Y yields, curve (2s10s), USD (DXY), equities, credit spreads, and gold—each with very low confidence. The low confidence is an implementation feature: because the speech explicitly says it is \"too soon to tell\" how AI affects monetary policy, the tool avoids forcing a directional trade and instead outputs \"neutral with low conviction,\" which reflects how traders often treat non-policy speeches.The Fed-Speak Decoder shows the mechanism behind the signals by quoting and translating key phrases. For example, \"too soon to tell\" is decoded as \"no firm policy conclusion,\" and \"humility\" language is decoded as \"data dependence; reduce conviction.\" Separately, the line citing that \"30 percent of contacts\" see AI as a salient risk and the warning that AI-sector leverage could increase are decoded as monitoring triggers—inputs that lift the financial-stability flag without implying immediate tightening.\nFinally, the tool generates a Scenario Tree that operationalizes the speech into decision-relevant branches: a base case of gradual AI integration with monitoring, a hawkish surprise path where inflation pressures or financial tightening emerge (e.g., leverage unwind), and a dovish surprise path where AI's macro effects are smaller and risks remain contained. The Risks & Triggers list then summarizes what the user should watch next—job displacement, cost pressures, sentiment shifts, and increasing leverage—so the output remains actionable even when the directional trade signal is neutral.\nValidation focuses on whether the tool produces interpretations that are consistent with widely accepted market reactions to Fed communications. To test this, sample FOMC statements and press conference transcripts are run through the tool and compared with real-world market commentary from financial news sources and analyst notes.\nRather than measuring predictive accuracy, validation centers on interpretive alignment. If the Fed's language is broadly considered hawkish by markets, the tool should reflect that tone and produce appropriately cautious or risk-off signals. Discrepancies are reviewed to determine whether they stem from missing context, ambiguous language, or limitations in the prompt design.\nUser feedback also plays a role in validation, particularly in assessing clarity. If users can explain the Fed's message more confidently after using the tool, it is considered effective, even if markets later move unpredictably.\nAt the evolve stage, the tool is designed to evolve as both the Federal Reserve and market dynamics change. Over time, the prompt can be refined to incorporate new linguistic patterns, such as emerging terminology related to financial stability or artificial intelligence-driven productivity.\nAdditional features could include comparative analysis between consecutive FOMC statements, automatic highlighting of changed wording, or region-specific impacts for global investors. The asset coverage could also be expanded to include international spillover effects or sector-level equity implications.\nAs users become more sophisticated, the tool could offer adjustable confidence thresholds or allow users to select a more conservative or aggressive interpretation mode, further personalizing the experience.\nThe last is the reflection. This project demonstrates how generative AI can be applied responsibly in financial contexts by focusing on interpretation rather than prediction. Translating Fed-speak into understandable signals does not eliminate uncertainty, but it reduces informational barriers and improves financial literacy.\nThrough the DRIVER process, the project highlights the importance of clear problem definition, thoughtful representation, and transparent reasoning. Most importantly, it reinforces that effective financial tools should empower users to think critically, not replace judgment. By making central bank communication more accessible, this tool helps users engage with macroeconomic policy in a more informed and confident way.Thank you!"
}